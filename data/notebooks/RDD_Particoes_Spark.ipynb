{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercícios RDD Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Command: /opt/java/bin/java -cp /etc/spark/:/opt/spark/jars/*:/etc/hadoop/:/etc/hadoop/*:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/tools/lib/* -Xmx1g org.apache.spark.deploy.master.Master --host localhost --port 7077 --webui-port 8080\r\n",
      "========================================\r\n",
      "20/03/18 20:31:09 INFO master.Master: Started daemon with process name: 1087@jupyter-notebook\r\n",
      "20/03/18 20:31:09 INFO util.SignalUtils: Registered signal handler for TERM\r\n",
      "20/03/18 20:31:09 INFO util.SignalUtils: Registered signal handler for HUP\r\n",
      "20/03/18 20:31:09 INFO util.SignalUtils: Registered signal handler for INT\r\n",
      "20/03/18 20:31:10 INFO spark.SecurityManager: Changing view acls to: root\r\n",
      "20/03/18 20:31:10 INFO spark.SecurityManager: Changing modify acls to: root\r\n",
      "20/03/18 20:31:10 INFO spark.SecurityManager: Changing view acls groups to: \r\n",
      "20/03/18 20:31:10 INFO spark.SecurityManager: Changing modify acls groups to: \r\n",
      "20/03/18 20:31:10 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\r\n",
      "20/03/18 20:31:10 INFO util.Utils: Successfully started service 'sparkMaster' on port 7077.\r\n",
      "20/03/18 20:31:10 INFO master.Master: Starting Spark master at spark://localhost:7077\r\n",
      "20/03/18 20:31:10 INFO master.Master: Running Spark version 2.4.1\r\n",
      "20/03/18 20:31:10 INFO util.log: Logging initialized @1454ms\r\n",
      "20/03/18 20:31:10 INFO server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown\r\n",
      "20/03/18 20:31:10 INFO server.Server: Started @1504ms\r\n",
      "20/03/18 20:31:10 INFO server.AbstractConnector: Started ServerConnector@5526ec85{HTTP/1.1,[http/1.1]}{0.0.0.0:8080}\r\n",
      "20/03/18 20:31:10 INFO util.Utils: Successfully started service 'MasterUI' on port 8080.\r\n",
      "20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@78c62b96{/app,null,AVAILABLE,@Spark}\r\n",
      "20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1330e23c{/app/json,null,AVAILABLE,@Spark}\r\n",
      "20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3f7fb168{/,null,AVAILABLE,@Spark}\r\n",
      "20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@50e5c33c{/json,null,AVAILABLE,@Spark}\r\n",
      "20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@44d0ea1e{/static,null,AVAILABLE,@Spark}\r\n",
      "20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2a362185{/app/kill,null,AVAILABLE,@Spark}\r\n",
      "20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@222db61{/driver/kill,null,AVAILABLE,@Spark}\r\n",
      "20/03/18 20:31:10 INFO ui.MasterWebUI: Bound MasterWebUI to 0.0.0.0, and started at http://jupyter-notebook:8080\r\n",
      "20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@58cb287e{/metrics/master/json,null,AVAILABLE,@Spark}\r\n",
      "20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3d2d7a89{/metrics/applications/json,null,AVAILABLE,@Spark}\r\n",
      "20/03/18 20:31:10 INFO master.Master: I have been elected leader! New state: ALIVE\r\n"
     ]
    }
   ],
   "source": [
    "# 1. Ler com RDD os arquivos localmente do diretório “/opt/spark/logs/” (\"file:///opt/spark/logs/\")\n",
    "# visualizando o que tem no arquivo # !ls /opt/spark/logs/\n",
    "# !ls /opt/spark/logs/\n",
    "!cat /opt/spark/logs/spark--org.apache.spark.deploy.master.Master-1-jupyter-notebook.out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lendo o arquivo /opt/spark/logs/ e armazenando numa variável \n",
    "# sc = spark content\n",
    "log = sc.textFile(\"file:///opt/spark/logs/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "# a) Contar a quantidade de linhas\n",
    "print(log.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Spark Command: /opt/java/bin/java -cp /etc/spark/:/opt/spark/jars/*:/etc/hadoop/:/etc/hadoop/*:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/tools/lib/* -Xmx1g org.apache.spark.deploy.master.Master --host localhost --port 7077 --webui-port 8080'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b) Visualizar a primeira linha\n",
    "log.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Spark Command: /opt/java/bin/java -cp /etc/spark/:/opt/spark/jars/*:/etc/hadoop/:/etc/hadoop/*:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/tools/lib/* -Xmx1g org.apache.spark.deploy.master.Master --host localhost --port 7077 --webui-port 8080',\n",
       " '========================================',\n",
       " '20/03/18 20:31:09 INFO master.Master: Started daemon with process name: 1087@jupyter-notebook',\n",
       " '20/03/18 20:31:09 INFO util.SignalUtils: Registered signal handler for TERM',\n",
       " '20/03/18 20:31:09 INFO util.SignalUtils: Registered signal handler for HUP',\n",
       " '20/03/18 20:31:09 INFO util.SignalUtils: Registered signal handler for INT',\n",
       " '20/03/18 20:31:10 INFO spark.SecurityManager: Changing view acls to: root',\n",
       " '20/03/18 20:31:10 INFO spark.SecurityManager: Changing modify acls to: root',\n",
       " '20/03/18 20:31:10 INFO spark.SecurityManager: Changing view acls groups to: ',\n",
       " '20/03/18 20:31:10 INFO spark.SecurityManager: Changing modify acls groups to: ',\n",
       " '20/03/18 20:31:10 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()',\n",
       " \"20/03/18 20:31:10 INFO util.Utils: Successfully started service 'sparkMaster' on port 7077.\",\n",
       " '20/03/18 20:31:10 INFO master.Master: Starting Spark master at spark://localhost:7077',\n",
       " '20/03/18 20:31:10 INFO master.Master: Running Spark version 2.4.1',\n",
       " '20/03/18 20:31:10 INFO util.log: Logging initialized @1454ms',\n",
       " '20/03/18 20:31:10 INFO server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown',\n",
       " '20/03/18 20:31:10 INFO server.Server: Started @1504ms',\n",
       " '20/03/18 20:31:10 INFO server.AbstractConnector: Started ServerConnector@5526ec85{HTTP/1.1,[http/1.1]}{0.0.0.0:8080}',\n",
       " \"20/03/18 20:31:10 INFO util.Utils: Successfully started service 'MasterUI' on port 8080.\",\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@78c62b96{/app,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1330e23c{/app/json,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3f7fb168{/,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@50e5c33c{/json,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@44d0ea1e{/static,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2a362185{/app/kill,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@222db61{/driver/kill,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO ui.MasterWebUI: Bound MasterWebUI to 0.0.0.0, and started at http://jupyter-notebook:8080',\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@58cb287e{/metrics/master/json,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3d2d7a89{/metrics/applications/json,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO master.Master: I have been elected leader! New state: ALIVE']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# muito cuidado pois dependendo to tamanho do arquivo trava e topa a memória\n",
    "# c) Visualizar todas as linhas\n",
    "log.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Spark',\n",
       " 'Command:',\n",
       " '/opt/java/bin/java',\n",
       " '-cp',\n",
       " '/etc/spark/:/opt/spark/jars/*:/etc/hadoop/:/etc/hadoop/*:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/tools/lib/*',\n",
       " '-Xmx1g',\n",
       " 'org.apache.spark.deploy.master.Master',\n",
       " '--host',\n",
       " 'localhost',\n",
       " '--port',\n",
       " '7077',\n",
       " '--webui-port',\n",
       " '8080',\n",
       " '========================================',\n",
       " '20/03/18',\n",
       " '20:31:09',\n",
       " 'INFO',\n",
       " 'master.Master:',\n",
       " 'Started',\n",
       " 'daemon',\n",
       " 'with',\n",
       " 'process',\n",
       " 'name:',\n",
       " '1087@jupyter-notebook',\n",
       " '20/03/18',\n",
       " '20:31:09',\n",
       " 'INFO',\n",
       " 'util.SignalUtils:',\n",
       " 'Registered',\n",
       " 'signal',\n",
       " 'handler',\n",
       " 'for',\n",
       " 'TERM',\n",
       " '20/03/18',\n",
       " '20:31:09',\n",
       " 'INFO',\n",
       " 'util.SignalUtils:',\n",
       " 'Registered',\n",
       " 'signal',\n",
       " 'handler',\n",
       " 'for',\n",
       " 'HUP',\n",
       " '20/03/18',\n",
       " '20:31:09',\n",
       " 'INFO',\n",
       " 'util.SignalUtils:',\n",
       " 'Registered',\n",
       " 'signal',\n",
       " 'handler',\n",
       " 'for',\n",
       " 'INT',\n",
       " '20/03/18',\n",
       " '20:31:10',\n",
       " 'INFO',\n",
       " 'spark.SecurityManager:',\n",
       " 'Changing',\n",
       " 'view',\n",
       " 'acls',\n",
       " 'to:',\n",
       " 'root',\n",
       " '20/03/18',\n",
       " '20:31:10',\n",
       " 'INFO',\n",
       " 'spark.SecurityManager:',\n",
       " 'Changing',\n",
       " 'modify',\n",
       " 'acls',\n",
       " 'to:',\n",
       " 'root',\n",
       " '20/03/18',\n",
       " '20:31:10',\n",
       " 'INFO',\n",
       " 'spark.SecurityManager:',\n",
       " 'Changing',\n",
       " 'view',\n",
       " 'acls',\n",
       " 'groups',\n",
       " 'to:',\n",
       " '',\n",
       " '20/03/18',\n",
       " '20:31:10',\n",
       " 'INFO',\n",
       " 'spark.SecurityManager:',\n",
       " 'Changing',\n",
       " 'modify',\n",
       " 'acls',\n",
       " 'groups',\n",
       " 'to:',\n",
       " '',\n",
       " '20/03/18',\n",
       " '20:31:10',\n",
       " 'INFO',\n",
       " 'spark.SecurityManager:',\n",
       " 'SecurityManager:',\n",
       " 'authentication',\n",
       " 'disabled;',\n",
       " 'ui',\n",
       " 'acls',\n",
       " 'disabled;',\n",
       " 'users',\n",
       " '',\n",
       " 'with',\n",
       " 'view',\n",
       " 'permissions:',\n",
       " 'Set(root);',\n",
       " 'groups',\n",
       " 'with',\n",
       " 'view',\n",
       " 'permissions:',\n",
       " 'Set();',\n",
       " 'users',\n",
       " '',\n",
       " 'with',\n",
       " 'modify',\n",
       " 'permissions:',\n",
       " 'Set(root);',\n",
       " 'groups',\n",
       " 'with',\n",
       " 'modify',\n",
       " 'permissions:',\n",
       " 'Set()',\n",
       " '20/03/18',\n",
       " '20:31:10',\n",
       " 'INFO',\n",
       " 'util.Utils:',\n",
       " 'Successfully',\n",
       " 'started',\n",
       " 'service',\n",
       " \"'sparkMaster'\",\n",
       " 'on',\n",
       " 'port',\n",
       " '7077.',\n",
       " '20/03/18',\n",
       " '20:31:10',\n",
       " 'INFO',\n",
       " 'master.Master:',\n",
       " 'Starting',\n",
       " 'Spark',\n",
       " 'master',\n",
       " 'at',\n",
       " 'spark://localhost:7077',\n",
       " '20/03/18',\n",
       " '20:31:10',\n",
       " 'INFO',\n",
       " 'master.Master:',\n",
       " 'Running',\n",
       " 'Spark',\n",
       " 'version',\n",
       " '2.4.1',\n",
       " '20/03/18',\n",
       " '20:31:10',\n",
       " 'INFO',\n",
       " 'util.log:',\n",
       " 'Logging',\n",
       " 'initialized',\n",
       " '@1454ms',\n",
       " '20/03/18',\n",
       " '20:31:10',\n",
       " 'INFO',\n",
       " 'server.Server:',\n",
       " 'jetty-9.3.z-SNAPSHOT,',\n",
       " 'build',\n",
       " 'timestamp:',\n",
       " 'unknown,',\n",
       " 'git',\n",
       " 'hash:',\n",
       " 'unknown',\n",
       " '20/03/18',\n",
       " '20:31:10',\n",
       " 'INFO',\n",
       " 'server.Server:',\n",
       " 'Started',\n",
       " '@1504ms',\n",
       " '20/03/18',\n",
       " '20:31:10',\n",
       " 'INFO',\n",
       " 'server.AbstractConnector:',\n",
       " 'Started',\n",
       " 'ServerConnector@5526ec85{HTTP/1.1,[http/1.1]}{0.0.0.0:8080}',\n",
       " '20/03/18',\n",
       " '20:31:10',\n",
       " 'INFO',\n",
       " 'util.Utils:',\n",
       " 'Successfully',\n",
       " 'started',\n",
       " 'service',\n",
       " \"'MasterUI'\",\n",
       " 'on',\n",
       " 'port',\n",
       " '8080.',\n",
       " '20/03/18',\n",
       " '20:31:10',\n",
       " 'INFO',\n",
       " 'handler.ContextHandler:',\n",
       " 'Started',\n",
       " 'o.s.j.s.ServletContextHandler@78c62b96{/app,null,AVAILABLE,@Spark}',\n",
       " '20/03/18',\n",
       " '20:31:10',\n",
       " 'INFO',\n",
       " 'handler.ContextHandler:',\n",
       " 'Started',\n",
       " 'o.s.j.s.ServletContextHandler@1330e23c{/app/json,null,AVAILABLE,@Spark}',\n",
       " '20/03/18',\n",
       " '20:31:10',\n",
       " 'INFO',\n",
       " 'handler.ContextHandler:',\n",
       " 'Started',\n",
       " 'o.s.j.s.ServletContextHandler@3f7fb168{/,null,AVAILABLE,@Spark}',\n",
       " '20/03/18',\n",
       " '20:31:10',\n",
       " 'INFO',\n",
       " 'handler.ContextHandler:',\n",
       " 'Started',\n",
       " 'o.s.j.s.ServletContextHandler@50e5c33c{/json,null,AVAILABLE,@Spark}',\n",
       " '20/03/18',\n",
       " '20:31:10',\n",
       " 'INFO',\n",
       " 'handler.ContextHandler:',\n",
       " 'Started',\n",
       " 'o.s.j.s.ServletContextHandler@44d0ea1e{/static,null,AVAILABLE,@Spark}',\n",
       " '20/03/18',\n",
       " '20:31:10',\n",
       " 'INFO',\n",
       " 'handler.ContextHandler:',\n",
       " 'Started',\n",
       " 'o.s.j.s.ServletContextHandler@2a362185{/app/kill,null,AVAILABLE,@Spark}',\n",
       " '20/03/18',\n",
       " '20:31:10',\n",
       " 'INFO',\n",
       " 'handler.ContextHandler:',\n",
       " 'Started',\n",
       " 'o.s.j.s.ServletContextHandler@222db61{/driver/kill,null,AVAILABLE,@Spark}',\n",
       " '20/03/18',\n",
       " '20:31:10',\n",
       " 'INFO',\n",
       " 'ui.MasterWebUI:',\n",
       " 'Bound',\n",
       " 'MasterWebUI',\n",
       " 'to',\n",
       " '0.0.0.0,',\n",
       " 'and',\n",
       " 'started',\n",
       " 'at',\n",
       " 'http://jupyter-notebook:8080',\n",
       " '20/03/18',\n",
       " '20:31:10',\n",
       " 'INFO',\n",
       " 'handler.ContextHandler:',\n",
       " 'Started',\n",
       " 'o.s.j.s.ServletContextHandler@58cb287e{/metrics/master/json,null,AVAILABLE,@Spark}',\n",
       " '20/03/18',\n",
       " '20:31:10',\n",
       " 'INFO',\n",
       " 'handler.ContextHandler:',\n",
       " 'Started',\n",
       " 'o.s.j.s.ServletContextHandler@3d2d7a89{/metrics/applications/json,null,AVAILABLE,@Spark}',\n",
       " '20/03/18',\n",
       " '20:31:10',\n",
       " 'INFO',\n",
       " 'master.Master:',\n",
       " 'I',\n",
       " 'have',\n",
       " 'been',\n",
       " 'elected',\n",
       " 'leader!',\n",
       " 'New',\n",
       " 'state:',\n",
       " 'ALIVE']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# d) Contar a quantidade de palavras\n",
    "# separar as palavras das linhas \n",
    "palavras = log.flatMap(lambda linha: linha.split(\" \"))\n",
    "#palavras.count()\n",
    "\n",
    "palavras.collect() #para visualizar a mudança \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Spark'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spark'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e) Converter todas as palavras em minúsculas\n",
    "palavras_minusculas = palavras.map(lambda palavra: palavra.lower())\n",
    "palavras_minusculas.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f) Remover as palavras de tamanho menor que 2\n",
    "palavra_menor2 = palavras_minusculas.filter(lambda palavra: len(palavra)>2)\n",
    "palavra_menor2.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('spark', 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# g) Atribuir o valor de 1 para cada palavra\n",
    "palavra_mais_1 = palavra_menor2.map(lambda palavra: (palavra, 1))\n",
    "palavra_mais_1.first()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# h) Contar as palavras com o mesmo nome\n",
    "# Juntar as palavras novamente\n",
    "palavras_reduce = palavra_mais_1.reduceByKey(lambda chave1, chave2, : chave1 + chave2)\n",
    "palavras_reduce.count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'masterui'\", 1),\n",
       " (\"'sparkmaster'\", 1),\n",
       " ('--host', 1),\n",
       " ('--port', 1),\n",
       " ('--webui-port', 1),\n",
       " ('-cp', 1),\n",
       " ('-xmx1g', 1),\n",
       " ('/etc/spark/:/opt/spark/jars/*:/etc/hadoop/:/etc/hadoop/*:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/tools/lib/*',\n",
       "  1),\n",
       " ('/opt/java/bin/java', 1),\n",
       " ('0.0.0.0,', 1),\n",
       " ('1087@jupyter-notebook', 1),\n",
       " ('2.4.1', 1),\n",
       " ('20/03/18', 28),\n",
       " ('20:31:09', 4),\n",
       " ('20:31:10', 24),\n",
       " ('7077', 1),\n",
       " ('7077.', 1),\n",
       " ('8080', 1),\n",
       " ('8080.', 1),\n",
       " ('========================================', 1),\n",
       " ('@1454ms', 1),\n",
       " ('@1504ms', 1),\n",
       " ('acls', 5),\n",
       " ('alive', 1),\n",
       " ('and', 1),\n",
       " ('authentication', 1),\n",
       " ('been', 1),\n",
       " ('bound', 1),\n",
       " ('build', 1),\n",
       " ('changing', 4),\n",
       " ('command:', 1),\n",
       " ('daemon', 1),\n",
       " ('disabled;', 2),\n",
       " ('elected', 1),\n",
       " ('for', 3),\n",
       " ('git', 1),\n",
       " ('groups', 4),\n",
       " ('handler', 3),\n",
       " ('handler.contexthandler:', 9),\n",
       " ('hash:', 1),\n",
       " ('have', 1),\n",
       " ('http://jupyter-notebook:8080', 1),\n",
       " ('hup', 1),\n",
       " ('info', 28),\n",
       " ('initialized', 1),\n",
       " ('int', 1),\n",
       " ('jetty-9.3.z-snapshot,', 1),\n",
       " ('leader!', 1),\n",
       " ('localhost', 1),\n",
       " ('logging', 1),\n",
       " ('master', 1),\n",
       " ('master.master:', 4),\n",
       " ('masterwebui', 1),\n",
       " ('modify', 4),\n",
       " ('name:', 1),\n",
       " ('new', 1),\n",
       " ('o.s.j.s.servletcontexthandler@1330e23c{/app/json,null,available,@spark}',\n",
       "  1),\n",
       " ('o.s.j.s.servletcontexthandler@222db61{/driver/kill,null,available,@spark}',\n",
       "  1),\n",
       " ('o.s.j.s.servletcontexthandler@2a362185{/app/kill,null,available,@spark}',\n",
       "  1),\n",
       " ('o.s.j.s.servletcontexthandler@3d2d7a89{/metrics/applications/json,null,available,@spark}',\n",
       "  1),\n",
       " ('o.s.j.s.servletcontexthandler@3f7fb168{/,null,available,@spark}', 1),\n",
       " ('o.s.j.s.servletcontexthandler@44d0ea1e{/static,null,available,@spark}', 1),\n",
       " ('o.s.j.s.servletcontexthandler@50e5c33c{/json,null,available,@spark}', 1),\n",
       " ('o.s.j.s.servletcontexthandler@58cb287e{/metrics/master/json,null,available,@spark}',\n",
       "  1),\n",
       " ('o.s.j.s.servletcontexthandler@78c62b96{/app,null,available,@spark}', 1),\n",
       " ('org.apache.spark.deploy.master.master', 1),\n",
       " ('permissions:', 4),\n",
       " ('port', 2),\n",
       " ('process', 1),\n",
       " ('registered', 3),\n",
       " ('root', 2),\n",
       " ('running', 1),\n",
       " ('securitymanager:', 1),\n",
       " ('server.abstractconnector:', 1),\n",
       " ('server.server:', 2),\n",
       " ('serverconnector@5526ec85{http/1.1,[http/1.1]}{0.0.0.0:8080}', 1),\n",
       " ('service', 2),\n",
       " ('set()', 1),\n",
       " ('set();', 1),\n",
       " ('set(root);', 2),\n",
       " ('signal', 3),\n",
       " ('spark', 3),\n",
       " ('spark.securitymanager:', 5),\n",
       " ('spark://localhost:7077', 1),\n",
       " ('started', 15),\n",
       " ('starting', 1),\n",
       " ('state:', 1),\n",
       " ('successfully', 2),\n",
       " ('term', 1),\n",
       " ('timestamp:', 1),\n",
       " ('to:', 4),\n",
       " ('ui.masterwebui:', 1),\n",
       " ('unknown', 1),\n",
       " ('unknown,', 1),\n",
       " ('users', 2),\n",
       " ('util.log:', 1),\n",
       " ('util.signalutils:', 3),\n",
       " ('util.utils:', 2),\n",
       " ('version', 1),\n",
       " ('view', 4),\n",
       " ('with', 5)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i) Visualizar em ordem alfabética\n",
    "palavras_ordem_alfabetica = palavras_reduce.sortBy(lambda palavra: palavra[0],True)\n",
    "palavras_ordem_alfabetica.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('20/03/18', 28),\n",
       " ('info', 28),\n",
       " ('20:31:10', 24),\n",
       " ('started', 15),\n",
       " ('handler.contexthandler:', 9),\n",
       " ('with', 5),\n",
       " ('spark.securitymanager:', 5),\n",
       " ('acls', 5),\n",
       " ('20:31:09', 4),\n",
       " ('master.master:', 4),\n",
       " ('groups', 4),\n",
       " ('permissions:', 4),\n",
       " ('changing', 4),\n",
       " ('view', 4),\n",
       " ('to:', 4),\n",
       " ('modify', 4),\n",
       " ('registered', 3),\n",
       " ('spark', 3),\n",
       " ('util.signalutils:', 3),\n",
       " ('signal', 3),\n",
       " ('handler', 3),\n",
       " ('for', 3),\n",
       " ('root', 2),\n",
       " ('disabled;', 2),\n",
       " ('set(root);', 2),\n",
       " ('successfully', 2),\n",
       " ('service', 2),\n",
       " ('server.server:', 2),\n",
       " ('users', 2),\n",
       " ('util.utils:', 2),\n",
       " ('port', 2),\n",
       " ('/opt/java/bin/java', 1),\n",
       " ('7077', 1),\n",
       " ('--webui-port', 1),\n",
       " ('8080', 1),\n",
       " ('daemon', 1),\n",
       " ('process', 1),\n",
       " ('term', 1),\n",
       " ('int', 1),\n",
       " ('securitymanager:', 1),\n",
       " ('set();', 1),\n",
       " ('set()', 1),\n",
       " (\"'sparkmaster'\", 1),\n",
       " ('starting', 1),\n",
       " ('master', 1),\n",
       " ('version', 1),\n",
       " ('2.4.1', 1),\n",
       " ('util.log:', 1),\n",
       " ('logging', 1),\n",
       " ('@1454ms', 1),\n",
       " ('jetty-9.3.z-snapshot,', 1),\n",
       " ('timestamp:', 1),\n",
       " ('git', 1),\n",
       " ('hash:', 1),\n",
       " ('unknown', 1),\n",
       " ('o.s.j.s.servletcontexthandler@1330e23c{/app/json,null,available,@spark}',\n",
       "  1),\n",
       " ('o.s.j.s.servletcontexthandler@44d0ea1e{/static,null,available,@spark}', 1),\n",
       " ('masterwebui', 1),\n",
       " ('o.s.j.s.servletcontexthandler@3d2d7a89{/metrics/applications/json,null,available,@spark}',\n",
       "  1),\n",
       " ('have', 1),\n",
       " ('leader!', 1),\n",
       " ('new', 1),\n",
       " ('state:', 1),\n",
       " ('command:', 1),\n",
       " ('-cp', 1),\n",
       " ('/etc/spark/:/opt/spark/jars/*:/etc/hadoop/:/etc/hadoop/*:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/tools/lib/*',\n",
       "  1),\n",
       " ('-xmx1g', 1),\n",
       " ('org.apache.spark.deploy.master.master', 1),\n",
       " ('--host', 1),\n",
       " ('localhost', 1),\n",
       " ('--port', 1),\n",
       " ('========================================', 1),\n",
       " ('name:', 1),\n",
       " ('1087@jupyter-notebook', 1),\n",
       " ('hup', 1),\n",
       " ('authentication', 1),\n",
       " ('7077.', 1),\n",
       " ('spark://localhost:7077', 1),\n",
       " ('running', 1),\n",
       " ('initialized', 1),\n",
       " ('build', 1),\n",
       " ('unknown,', 1),\n",
       " ('@1504ms', 1),\n",
       " ('server.abstractconnector:', 1),\n",
       " ('serverconnector@5526ec85{http/1.1,[http/1.1]}{0.0.0.0:8080}', 1),\n",
       " (\"'masterui'\", 1),\n",
       " ('8080.', 1),\n",
       " ('o.s.j.s.servletcontexthandler@78c62b96{/app,null,available,@spark}', 1),\n",
       " ('o.s.j.s.servletcontexthandler@3f7fb168{/,null,available,@spark}', 1),\n",
       " ('o.s.j.s.servletcontexthandler@50e5c33c{/json,null,available,@spark}', 1),\n",
       " ('o.s.j.s.servletcontexthandler@2a362185{/app/kill,null,available,@spark}',\n",
       "  1),\n",
       " ('o.s.j.s.servletcontexthandler@222db61{/driver/kill,null,available,@spark}',\n",
       "  1),\n",
       " ('ui.masterwebui:', 1),\n",
       " ('bound', 1),\n",
       " ('0.0.0.0,', 1),\n",
       " ('and', 1),\n",
       " ('http://jupyter-notebook:8080', 1),\n",
       " ('o.s.j.s.servletcontexthandler@58cb287e{/metrics/master/json,null,available,@spark}',\n",
       "  1),\n",
       " ('been', 1),\n",
       " ('elected', 1),\n",
       " ('alive', 1)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# j) Visualizar em ordem decrescente a quantidade de palavras\n",
    "palavras_ordem_alfabetica_qtd = palavras_reduce.sortBy(lambda palavra: palavra[1],False)\n",
    "palavras_ordem_alfabetica_qtd.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('20/03/18', 28),\n",
       " ('info', 28),\n",
       " ('20:31:10', 24),\n",
       " ('started', 15),\n",
       " ('handler.contexthandler:', 9),\n",
       " ('with', 5),\n",
       " ('spark.securitymanager:', 5),\n",
       " ('acls', 5),\n",
       " ('20:31:09', 4),\n",
       " ('master.master:', 4),\n",
       " ('groups', 4),\n",
       " ('permissions:', 4),\n",
       " ('changing', 4),\n",
       " ('view', 4),\n",
       " ('to:', 4),\n",
       " ('modify', 4),\n",
       " ('registered', 3),\n",
       " ('spark', 3),\n",
       " ('util.signalutils:', 3),\n",
       " ('signal', 3),\n",
       " ('handler', 3),\n",
       " ('for', 3),\n",
       " ('root', 2),\n",
       " ('disabled;', 2),\n",
       " ('set(root);', 2),\n",
       " ('successfully', 2),\n",
       " ('service', 2),\n",
       " ('server.server:', 2),\n",
       " ('users', 2),\n",
       " ('util.utils:', 2),\n",
       " ('port', 2)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# j) k) Remover as palavras, com a quantidade de palavras > 1\n",
    "# selecionando o elemento do array que tem a quantidade no caso o elemento 1 pois 0 é a palavra\n",
    "palavra_qtd_maior_1 = palavras_ordem_alfabetica_qtd.filter(lambda palavra: palavra[1]>1)\n",
    "palavra_qtd_maior_1.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l) Salvar o RDD no diretorio do HDFS /user/<seu-nome>/logs_count_word\n",
    "palavra_qtd_maior_1.saveAsTextFile(\"/user/marcos/logs_palavras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\r\n",
      "-rw-r--r--   2 root supergroup          0 2021-06-24 23:44 /user/marcos/logs_palavras/_SUCCESS\r\n",
      "-rw-r--r--   2 root supergroup        517 2021-06-24 23:44 /user/marcos/logs_palavras/part-00000\r\n",
      "-rw-r--r--   2 root supergroup          0 2021-06-24 23:44 /user/marcos/logs_palavras/part-00001\r\n"
     ]
    }
   ],
   "source": [
    "# verificando se o arquivo foi salvo no hdfs /user/marcos/\n",
    "!hdfs dfs -ls /user/marcos/logs_palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercicios de RDD Partições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Ler com RDD os arquivos localmente do diretório “/opt/spark/logs/” (\"file:///opt/spark/logs/\") com 10 partições\n",
    "# por padrão vem duas partições\n",
    "log_particoes = sc.textFile(\"file:///opt/spark/logs/\")\n",
    "# visualizando a quantidade de partições\n",
    "log_particoes.getNumPartitions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alterando a quantidade de partições do arquivo para 5 partições, partições é bom ter gigas e não megas\n",
    "log_particoes = sc.textFile(\"file:///opt/spark/logs/\",5)\n",
    "log_particoes.getNumPartitions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Contar a quantidade de cada palavras em ordem decrescente do RDD em 5 partições\n",
    "palavras_particoes = log_particoes.flatMap(lambda linha: linha.split(\" \"),6)\n",
    "palavras_particoes.getNumPartitions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras_minusculas_particoes = palavras_particoes.map(lambda palavra: palavra.lower(),7)\n",
    "palavras_minusculas_particoes.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavra_count_particoes = palavras_particoes.map(lambda palavra:(palavra,1),8)\n",
    "palavra_count_particoes.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usando o reduce tem como fazer a alteração das Partições\n",
    "palavras_reduce_particoes = palavra_count_particoes.reduceByKey(lambda x,y : x+y,5)\n",
    "palavras_reduce_particoes.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Salvar o RDD no diretório do HDFS /user/<seu-nome>/logs_count_word_5\n",
    "palavras_reduce_particoes.saveAsTextFile(\"/user/marcos/logs_count_word_5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 items\r\n",
      "-rw-r--r--   2 root supergroup          0 2021-06-25 00:18 /user/marcos/logs_count_word_5/_SUCCESS\r\n",
      "-rw-r--r--   2 root supergroup        542 2021-06-25 00:18 /user/marcos/logs_count_word_5/part-00000\r\n",
      "-rw-r--r--   2 root supergroup        497 2021-06-25 00:18 /user/marcos/logs_count_word_5/part-00001\r\n",
      "-rw-r--r--   2 root supergroup        553 2021-06-25 00:18 /user/marcos/logs_count_word_5/part-00002\r\n",
      "-rw-r--r--   2 root supergroup        794 2021-06-25 00:18 /user/marcos/logs_count_word_5/part-00003\r\n",
      "-rw-r--r--   2 root supergroup        413 2021-06-25 00:18 /user/marcos/logs_count_word_5/part-00004\r\n"
     ]
    }
   ],
   "source": [
    "# verificando o arquivo e suas partições\n",
    "!hdfs dfs -ls /user/marcos/logs_count_word_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('--port', 1),\n",
       " ('20:31:09', 4),\n",
       " ('daemon', 1),\n",
       " ('process', 1),\n",
       " ('registered', 3),\n",
       " ('signal', 3),\n",
       " ('20:31:10', 24),\n",
       " ('to:', 4),\n",
       " ('groups', 4),\n",
       " ('', 4),\n",
       " ('authentication', 1),\n",
       " ('users', 2),\n",
       " ('permissions:', 4),\n",
       " ('on', 2),\n",
       " ('starting', 1),\n",
       " ('at', 2),\n",
       " ('2.4.1', 1),\n",
       " ('util.log:', 1),\n",
       " ('timestamp:', 1),\n",
       " ('@1504ms', 1),\n",
       " (\"'masterui'\", 1),\n",
       " ('o.s.j.s.servletcontexthandler@2a362185{/app/kill,null,available,@spark}',\n",
       "  1),\n",
       " ('o.s.j.s.servletcontexthandler@222db61{/driver/kill,null,available,@spark}',\n",
       "  1),\n",
       " ('to', 1),\n",
       " ('0.0.0.0,', 1),\n",
       " ('http://jupyter-notebook:8080', 1),\n",
       " ('have', 1),\n",
       " ('elected', 1),\n",
       " ('alive', 1),\n",
       " ('command:', 1),\n",
       " ('-cp', 1),\n",
       " ('info', 28),\n",
       " ('int', 1),\n",
       " ('acls', 5),\n",
       " ('modify', 4),\n",
       " ('util.utils:', 2),\n",
       " ('7077.', 1),\n",
       " ('master', 1),\n",
       " ('jetty-9.3.z-snapshot,', 1),\n",
       " ('8080.', 1),\n",
       " ('bound', 1),\n",
       " ('masterwebui', 1),\n",
       " ('and', 1),\n",
       " ('/opt/java/bin/java', 1),\n",
       " ('org.apache.spark.deploy.master.master', 1),\n",
       " ('8080', 1),\n",
       " ('20/03/18', 28),\n",
       " ('name:', 1),\n",
       " ('util.signalutils:', 3),\n",
       " ('handler', 3),\n",
       " ('for', 3),\n",
       " ('successfully', 2),\n",
       " ('service', 2),\n",
       " ('running', 1),\n",
       " ('version', 1),\n",
       " ('logging', 1),\n",
       " ('@1454ms', 1),\n",
       " ('server.server:', 2),\n",
       " ('unknown', 1),\n",
       " ('server.abstractconnector:', 1),\n",
       " ('o.s.j.s.servletcontexthandler@44d0ea1e{/static,null,available,@spark}', 1),\n",
       " ('been', 1),\n",
       " ('leader!', 1),\n",
       " ('new', 1),\n",
       " ('/etc/spark/:/opt/spark/jars/*:/etc/hadoop/:/etc/hadoop/*:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/tools/lib/*',\n",
       "  1),\n",
       " ('localhost', 1),\n",
       " ('--webui-port', 1),\n",
       " ('started', 15),\n",
       " ('changing', 4),\n",
       " ('securitymanager:', 1),\n",
       " ('disabled;', 2),\n",
       " ('set(root);', 2),\n",
       " ('set();', 1),\n",
       " (\"'sparkmaster'\", 1),\n",
       " ('spark://localhost:7077', 1),\n",
       " ('initialized', 1),\n",
       " ('git', 1),\n",
       " ('hash:', 1),\n",
       " ('o.s.j.s.servletcontexthandler@78c62b96{/app,null,available,@spark}', 1),\n",
       " ('o.s.j.s.servletcontexthandler@50e5c33c{/json,null,available,@spark}', 1),\n",
       " ('spark', 3),\n",
       " ('-xmx1g', 1),\n",
       " ('--host', 1),\n",
       " ('7077', 1),\n",
       " ('========================================', 1),\n",
       " ('master.master:', 4),\n",
       " ('with', 5),\n",
       " ('1087@jupyter-notebook', 1),\n",
       " ('term', 1),\n",
       " ('hup', 1),\n",
       " ('spark.securitymanager:', 5),\n",
       " ('view', 4),\n",
       " ('root', 2),\n",
       " ('ui', 1),\n",
       " ('set()', 1),\n",
       " ('port', 2),\n",
       " ('build', 1),\n",
       " ('unknown,', 1),\n",
       " ('serverconnector@5526ec85{http/1.1,[http/1.1]}{0.0.0.0:8080}', 1),\n",
       " ('handler.contexthandler:', 9),\n",
       " ('o.s.j.s.servletcontexthandler@1330e23c{/app/json,null,available,@spark}',\n",
       "  1),\n",
       " ('o.s.j.s.servletcontexthandler@3f7fb168{/,null,available,@spark}', 1),\n",
       " ('ui.masterwebui:', 1),\n",
       " ('o.s.j.s.servletcontexthandler@58cb287e{/metrics/master/json,null,available,@spark}',\n",
       "  1),\n",
       " ('o.s.j.s.servletcontexthandler@3d2d7a89{/metrics/applications/json,null,available,@spark}',\n",
       "  1),\n",
       " ('i', 1),\n",
       " ('state:', 1)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Refazer a questão 2, com todas as funções na mesma linha de um RDD\n",
    "palavras_particoes_linha = log_particoes.flatMap(lambda linha: linha.split(\" \")).map(lambda palavra: palavra.lower()).map(lambda palavra:(palavra,1)).reduceByKey(lambda x,y : x+y,5)\n",
    "palavras_particoes_linha.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
